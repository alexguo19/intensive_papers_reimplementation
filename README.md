# intensive_papers_reimplementation
code reimplementation of intensive papers
AI & Deep Learning Papers (Chronological Collection)
A curated list of influential machine learning / deep learning papers, organized by publication year.
1997
⦁	Long Short-Term Memory
2004
⦁	ROUGE: A Package for Automatic Evaluation of Summaries
2010
⦁	Understanding the Difficulty of Training Deep Feedforward Neural Networks
2012
⦁	ImageNet Classification with Deep Convolutional Neural Networks
2013
⦁	Efficient Estimation of Word Representations in Vector Space
⦁	On the Difficulty of Training Recurrent Neural Networks
⦁	Playing Atari with Deep Reinforcement Learning
2014
⦁	Dropout: A Simple Way to Prevent Neural Networks from Overfitting
⦁	Conditional Generative Adversarial Nets
⦁	Convolutional Neural Networks for Sentence Classification
⦁	Deep Speech: Scaling Up End-to-End Speech Recognition
⦁	Generative Adversarial Networks
⦁	Going Deeper with Convolutions
⦁	Neural Turing Machines
⦁	Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation
⦁	Sequence to Sequence Learning with Neural Networks
2015
⦁	Adam: A Method for Stochastic Optimization
⦁	Neural Machine Translation by Jointly Learning to Align and Translate
⦁	Very Deep Convolutional Networks for Large-Scale Image Recognition
⦁	Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift
⦁	Deep Residual Learning for Image Recognition
⦁	Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification
⦁	Distilling the Knowledge in a Neural Network
⦁	Fast R-CNN
⦁	Fully Convolutional Networks for Semantic Segmentation
⦁	U-Net: Convolutional Networks for Biomedical Image Segmentation
⦁	Pointer Networks
⦁	Order Matters: Sequence to Sequence for Sets
⦁	Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks
⦁	Generative Models of Neural Language Modeling
⦁	Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks
2016
⦁	Layer Normalization
⦁	Multi-Scale Context Aggregation by Dilated Convolutions
⦁	RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic Segmentation
⦁	Spatial Transformer Networks
⦁	SSD: Single Shot MultiBox Detector
⦁	You Only Look Once: Unified, Real-Time Object Detection
2017
⦁	Dilated Convolutional Networks
⦁	Neural Architecture Search with Reinforcement Learning
⦁	Attention Is All You Need
⦁	Neural Discrete Representation Learning
⦁	Aggregated Residual Transformations for Deep Neural Networks (ResNeXt)
⦁	DSSD: Deconvolutional Single Shot Detector
⦁	Feature Pyramid Networks for Object Detection
⦁	MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications
⦁	ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices
⦁	Group Normalization
2018
⦁	Image Transformer
⦁	Neural Ordinary Differential Equations
⦁	Densely Connected Convolutional Networks (DenseNet)
⦁	Efficient Neural Architecture Search via Parameter Sharing
⦁	Focal Loss for Dense Object Detection
⦁	Improving Language Understanding by Generative Pre-Training
⦁	Independently Recurrent Neural Network (IndRNN)
⦁	Mask R-CNN
⦁	Matrix Capsules with EM Routing
⦁	Self-Attention with Relative Position Representations
⦁	ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design
⦁	Recurrent Neural Units for Highly Parallelizable Recurrence
⦁	CornerNet: Detecting Objects as Paired Keypoints
⦁	Large Language Models Are Few-Shot Learners
2019
⦁	Searching for MobileNetV3
⦁	DARTS: Differentiable Architecture Search
⦁	GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding
⦁	SNAS: Stochastic Neural Architecture Search
⦁	The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks
⦁	EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks
⦁	Parameter-Efficient Transfer Learning for NLP
⦁	IntroVAE: Introspective Variational Autoencoders for Photographic Image Synthesis
⦁	AutoAugment: Learning Augmentation Strategies from Data
⦁	BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
⦁	Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization
⦁	MobileNetV2: Inverted Residuals and Linear Bottlenecks
⦁	RoBERTa: A Robustly Optimized BERT Pretraining Approach
⦁	Spider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Text-to-SQL
⦁	Squeeze-and-Excitation Networks
⦁	Freezing Layers During Transformer Fine-Tuning Improves Stability and Performance
2020
⦁	BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension
⦁	ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators
⦁	Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer (T5)
⦁	Denoising Diffusion Probabilistic Models
⦁	Learning to Summarize with Human Feedback
⦁	EfficientDet: Scalable and Efficient Object Detection
⦁	End-to-End Object Detection with Transformers (DETR)
⦁	Noisy Student Training for Robust Image Classification
⦁	Language Models Are Unsupervised Multitask Learners (GPT-3)
⦁	Scaling Laws for Neural Language Models
2021
⦁	An Image is Worth 16×16 Words: Transformers for Image Recognition at Scale (ViT)
⦁	Deformable DETR
⦁	Massive Multitask Language Understanding (MMLU)
⦁	mT5: A Massively Multilingual Pre-trained Text-to-Text Transformer
⦁	Neural Networks with Fixed Sparse Masks
⦁	Transformer in Transformer (TNT)
⦁	AdapterFusion
⦁	Counterfactual Vision Learning
⦁	Evaluating Large Language Models Trained on Code
⦁	Learning Transferable Visual Models From Natural Language Supervision (CLIP)
⦁	LoRA: Low-Rank Adaptation of Large Language Models
⦁	Prefix-Tuning: Optimizing Continuous Prompts for Generation
⦁	Raise a Child in Large Language Model
⦁	Swin Transformer: Hierarchical Vision Transformer
⦁	High-Resolution Image Synthesis with Latent Diffusion Models
⦁	The Power of Scale for Parameter-Efficient Prompt Tuning
⦁	Data-Efficient Image Transformers
⦁	Transformer Feed-Forward Layers Are Key-Value Memories
⦁	What Makes Good In-Context Learning Examples?
⦁	Zero-Shot Text-to-Image Generation (DALL·E 2)
2022
⦁	Visual Prompt Tuning
⦁	Finetuned Language Models Are Zero-Shot Learners
⦁	Multitask Prompted Training Enables Zero-Shot Generalization
⦁	Efficient Scaling of Large Language Models with Sparse Mixture-of-Experts
⦁	Chain-of-Thought Prompting Elicits Reasoning in Large Language Models
⦁	Auto-Encoding Variational Bayes — Revisited in Modern Deep Learning Context
⦁	Automatic Chain-of-Thought Prompting in Large Language Models
⦁	SPoT: Better Prompt Tuning via Soft Prompt Transfer
⦁	Scaling Laws Revisited for Large Language Models
2023
⦁	Visual Instruction Tuning
2024
⦁	Tuning Language Models by Proxy
⦁	OpenChat: Advancing Open-Source Language Models through Alignment
⦁	ReVA: Random Vector Adaptation for Efficient LLM Tuning
⦁	NeXT-GPT: Any-to-Any Multimodal Large Language Model
⦁	A Survey on In-Context Learning
⦁	Better Zero-Shot Reasoning with Role-Play Prompting
⦁	DeepSeek-V2
⦁	DINOv2: Learning Robust Visual Representations
⦁	Efficient LLMs: A Survey
⦁	GraphRAG
⦁	GPT-4 Technical Report
⦁	Graph-of-Thoughts: Solving Problems with Structured Reasoning in LLMs
⦁	Improved Baselines for Visual Instruction Tuning
⦁	Mamba: Linear-Time Sequence Modeling with Selective State Spaces
⦁	Segment Anything Model 2 (SAM 2)
⦁	Scaling Down to Scale Up: Parameter-Efficient Tuning Strategies
⦁	Self-Prompting Large Language Models
⦁	The Mystery of In-Context Learning
⦁	A Survey of Large Language Models
2025
⦁	DINOv3
⦁	Instruction Tuning for Large Language Models: A Survey
⦁	Learning at Test Time with Expressive Hidden-State Recurrent Neural Networks
⦁	Segment Anything Model 3 (SAM 3)
